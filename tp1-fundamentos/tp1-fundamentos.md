# Trabajo Práctico 1 - Fundamentos

## Ejercicio 1

### Fundamentos Filosóficos

¿Cómo funcionan las mentes? ¿Es posible que las máquinas actúen de forma inteligente como lo hacen las personas y, si lo hicieran, tendrían mentes reales y conscientes? ¿Cuáles son las implicaciones éticas de las máquinas inteligentes?

La afirmación de que las máquinas podrían actuar como si fueran inteligentes se denomina hipótesis débil de la IA, y la afirmación de que las máquinas que lo hacen realmente piensan (no sólo simulan pensar) se denomina hipótesis fuerte de la IA.

#### IA débil: ¿pueden las máquinas actuar con inteligencia?

La IA se fundó en el supuesto de que la IA débil es posible Se define la IA como la búsqueda del mejor programa agente en una arquitectura determinada. Con esta formulación, la IA es posible por definición: para cualquier arquitectura digital con k bits de almacenamiento de programas existen exactamente 2^k programas agentes, y todo lo que tenemos que hacer para encontrar el mejor es enumerarlos y probarlos todos

##### El argumento de la discapacidad

> La afirmación de que "una máquina nunca puede hacer X".

Los ordenadores pueden hacer muchas cosas tan bien o mejor que los humanos, incluso cosas que la gente cree que requieren una gran perspicacia y comprensión humanas.
Las primeras conjeturas sobre los procesos mentales necesarios para producir un determinado comportamiento suelen ser erróneas. También es cierto, por supuesto, que hay muchas tareas en las que los ordenadores aún no destacan, incluida la prueba de Turing.

##### La objeción matemática

> Las máquinas son sistemas formales que están limitados por el teorema de incompletitud -no pueden establecer la verdad de su propia sentencia Gödel mientras que los humanos no tienen esa limitación.

##### El argumento de la informalidad
 
> La incapacidad de capturar todo en un conjunto de reglas lógicas se denomina problema de cualificación. Los agentes lógicos son vulnerables al problema de la cualificación

No se dirige contra los ordenadores en sí, sino contra una forma concreta de programarlos

#### IA fuerte: ¿pueden las máquinas pensar de verdad?

## Ejercicio 3

El artículo hace los siguientes comentarios:

### Dehumanización:

Bender: La utilización de modelos de lenguaje generativos puede llevar a una falta de percepción de la humanidad real, al blurring de las líneas entre seres humanos y máquinas, lo cual contribuye a la dehumanización.

### Impacto Ético y Moral:

Blake Lemoine: El uso de chatbots en objetos como muñecas sexuales puede llevar a una habituación de las personas a tratar a entidades que parecen humanas como si no lo fueran, lo cual plantea serias cuestiones éticas sobre el tratamiento de estos sistemas.

### Problemas con el Concepto de Significado:

Bender: Los LLMs pueden perpetuar problemas lingüísticos y culturales sin tener un entendimiento real del significado, lo cual es problemático porque los modelos procesan lenguaje de manera probabilística, sin referencia a la realidad o al significado profundo.

### Narcisismo Tecnológico:

Judith Butler: La idea de que la tecnología puede lograr lo que se considera distintivamente humano o mejorar la humanidad puede llevar a una forma de narcisismo tecnológico, donde se busca demostrar que las máquinas pueden superar a los humanos en todas las capacidades.

### Creación de "Personas Falsas":

Daniel Dennett: La creación de "personas falsas" o entidades artificiales que imitan a los humanos plantea riesgos serios, ya que estas máquinas no tienen la capacidad de experimentar realmente la humanidad, lo cual puede llevar a una falta de responsabilidad y a la creación de "armas" que amenazan la estabilidad social.

### Riesgos de Confusión y Mal Uso:

Bender: La confusión y el mal uso potencial de los LLMs pueden resultar en una erosión de las barreras entre lo que es verdaderamente humano y lo que es artificial, lo cual puede tener consecuencias peligrosas para la sociedad.

### Defensa

Desde mí perspectiva no estoy de acuerdo con la mayoría del artículo.

Humanizar cosas no humanas es algo que hemos hecho mucho antes de que existieran las computadoras. Les damos nombres propios a nuestras mascotas, les hablamos como si nos entendieran, etc. Lo considero un comportamiento usual, el artículo no proporciona ningún fundamento para creer que esto contribuye a deshumanizar a otras personas, y no conozco ninguno.

Por otro lado, el punto de vista de Lemoine casi inverso al anterior, tampoco ofrece ningún fundamento. La deshumanización ha existido siempre y es anterior a las computadoras. Aunque actualmente la esclavitud y prácticas similares son ilegales en países occidentales, como sociedad debemos buscar combatirlas, y argumentos vagos y vacíos como este no contribuyen.

El punto de vista de Bender me parece válido. Los LLMs no representan a todas las personas por igual. Lo que puedan generar depende de los datos con los que fueron entrenados. Y si eventualmente se quieren utilizar para crear máquinas iguales a las personas, ese concepto de "persona" estaría sesgado.

La opinión de Judith Butler me parece puramente subjetivo. Ella hace un juicio de valor acerca de los objetivos que pueda tener la sociedad. No es discutible.

Estoy de acuerdo con la idea de Daniel Dennett y Bender. Pero como sociedad estamos ante la disyuntiva de desarrollar nuevas herramientas que puedan ser mal utilizadas o buscar la ignorancia.
