# Trabajo Práctico 1 - Fundamentos

## Ejercicio 3

El artículo hace los siguientes comentarios:

### Dehumanización:

Bender: La utilización de modelos de lenguaje generativos puede llevar a una falta de percepción de la humanidad real, al blurring de las líneas entre seres humanos y máquinas, lo cual contribuye a la dehumanización.

### Impacto Ético y Moral:

Blake Lemoine: El uso de chatbots en objetos como muñecas sexuales puede llevar a una habituación de las personas a tratar a entidades que parecen humanas como si no lo fueran, lo cual plantea serias cuestiones éticas sobre el tratamiento de estos sistemas.

### Problemas con el Concepto de Significado:

Bender: Los LLMs pueden perpetuar problemas lingüísticos y culturales sin tener un entendimiento real del significado, lo cual es problemático porque los modelos procesan lenguaje de manera probabilística, sin referencia a la realidad o al significado profundo.

### Narcisismo Tecnológico:

Judith Butler: La idea de que la tecnología puede lograr lo que se considera distintivamente humano o mejorar la humanidad puede llevar a una forma de narcisismo tecnológico, donde se busca demostrar que las máquinas pueden superar a los humanos en todas las capacidades.

### Creación de "Personas Falsas":

Daniel Dennett: La creación de "personas falsas" o entidades artificiales que imitan a los humanos plantea riesgos serios, ya que estas máquinas no tienen la capacidad de experimentar realmente la humanidad, lo cual puede llevar a una falta de responsabilidad y a la creación de "armas" que amenazan la estabilidad social.

### Riesgos de Confusión y Mal Uso:

Bender: La confusión y el mal uso potencial de los LLMs pueden resultar en una erosión de las barreras entre lo que es verdaderamente humano y lo que es artificial, lo cual puede tener consecuencias peligrosas para la sociedad.

### Defensa

Desde mí perspectiva no estoy de acuerdo con la mayoría del artículo.

Humanizar cosas no humanas es algo que hemos hecho mucho antes de que existieran las computadoras. Les damos nombres propios a nuestras mascotas, les hablamos como si nos entendieran, etc. Lo considero un comportamiento usual, el artículo no proporciona ningún fundamento para creer que esto contribuye a deshumanizar a otras personas, y no conozco ninguno.

Por otro lado, el punto de vista de Lemoine casi inverso al anterior, tampoco ofrece ningún fundamento. La deshumanización ha existido siempre y es anterior a las computadoras. Aunque actualmente la esclavitud y prácticas similares son ilegales en países occidentales, como sociedad debemos buscar combatirlas, y argumentos vagos y vacíos como este no contribuyen.

El punto de vista de Bender me parece válido. Los LLMs no representan a todas las personas por igual. Lo que puedan generar depende de los datos con los que fueron entrenados. Y si eventualmente se quieren utilizar para crear máquinas iguales a las personas, ese concepto de "persona" estaría sesgado.

La opinión de Judith Butler me parece puramente subjetivo. Ella hace un juicio de valor acerca de los objetivos que pueda tener la sociedad. No es discutible.

Estoy de acuerdo con la idea de Daniel Dennett y Bender. Pero como sociedad estamos ante la disyuntiva de desarrollar nuevas herramientas que puedan ser mal utilizadas o buscar la ignorancia.
