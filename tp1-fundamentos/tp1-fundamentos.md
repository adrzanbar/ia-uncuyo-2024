# Trabajo Práctico 1 - Fundamentos

## Ejercicio 1

### Fundamentos Filosóficos

¿Cómo funcionan las mentes? ¿Es posible que las máquinas actúen de forma inteligente como lo hacen las personas y, si lo hicieran, tendrían mentes reales y conscientes? ¿Cuáles son las implicaciones éticas de las máquinas inteligentes?

La afirmación de que las máquinas podrían actuar como si fueran inteligentes se denomina hipótesis débil de la IA, y la afirmación de que las máquinas que lo hacen realmente piensan (no sólo simulan pensar) se denomina hipótesis fuerte de la IA.

#### IA débil: ¿pueden las máquinas actuar con inteligencia?

La IA se fundó en el supuesto de que la IA débil es posible Se define la IA como la búsqueda del mejor programa agente en una arquitectura determinada. Con esta formulación, la IA es posible por definición: para cualquier arquitectura digital con k bits de almacenamiento de programas existen exactamente 2^k programas agentes, y todo lo que tenemos que hacer para encontrar el mejor es enumerarlos y probarlos todos

##### El argumento de la discapacidad

> La afirmación de que "una máquina nunca puede hacer X".

Los ordenadores pueden hacer muchas cosas tan bien o mejor que los humanos, incluso cosas que la gente cree que requieren una gran perspicacia y comprensión humanas.
Las primeras conjeturas sobre los procesos mentales necesarios para producir un determinado comportamiento suelen ser erróneas. También es cierto, por supuesto, que hay muchas tareas en las que los ordenadores aún no destacan, incluida la prueba de Turing.

##### La objeción matemática

> Las máquinas son sistemas formales que están limitados por el teorema de incompletitud -no pueden establecer la verdad de su propia sentencia Gödel mientras que los humanos no tienen esa limitación.

El teorema de incompletitud de Gödel sólo se aplica a los sistemas formales lo suficientemente potentes como para realizar operaciones aritméticas. Esto incluye las máquinas de Turing. Las máquinas de Turing son infinitas, mientras que los ordenadores son finitos, por lo que cualquier ordenador puede describirse como un sistema (muy grande) en lógica proposicional, que no está sujeto al teorema de incompletitud de Gödel. Los seres humanos se comportaron de forma inteligente durante miles de años antes de que inventaran las matemáticas, por lo que es poco probable que el razonamiento matemático formal desempeñe algo más que un papel periférico en lo que significa ser inteligente. Incluso si admitimos que los ordenadores tienen limitaciones en lo que pueden demostrar, no hay pruebas de que los humanos sean inmunes a esas limitaciones.

##### El argumento de la informalidad
 
> La incapacidad de capturar todo en un conjunto de reglas lógicas se denomina problema de cualificación. Los agentes lógicos son vulnerables al problema de la cualificación

La postura que se dio en llamar "IA a la antigua", o GOFAI, sostiene que todo comportamiento inteligente puede ser capturado por un sistema que razona lógicamente a partir de un conjunto de hechos y reglas que describen el dominio. Por tanto, corresponde al agente lógico más simple. No se dirige contra los ordenadores en sí, sino contra una forma concreta de programarlos.
Muchas de estas cuestiones, el problema de la cualificación, la incertidumbre, el aprendizaje, las formas compiladas de toma de decisiones, se han incorporado ya al diseño estándar de agentes inteligentes. Esto demuestra el progreso de la IA, no su imposibilidad.
Para entender cómo funcionan los agentes humanos (o de otros animales), tenemos que considerar el agente en su totalidad, no sólo el programa del agente. De hecho, el enfoque de la cognición incorporada afirma que no tiene sentido considerar el cerebro por separado: la cognición tiene lugar dentro de un cuerpo, que está integrado en un entorno.

#### IA fuerte: ¿pueden las máquinas pensar de verdad?

## Ejercicio 3

El artículo hace los siguientes comentarios:

### Dehumanización:

Bender: La utilización de modelos de lenguaje generativos puede llevar a una falta de percepción de la humanidad real, al blurring de las líneas entre seres humanos y máquinas, lo cual contribuye a la dehumanización.

### Impacto Ético y Moral:

Blake Lemoine: El uso de chatbots en objetos como muñecas sexuales puede llevar a una habituación de las personas a tratar a entidades que parecen humanas como si no lo fueran, lo cual plantea serias cuestiones éticas sobre el tratamiento de estos sistemas.

### Problemas con el Concepto de Significado:

Bender: Los LLMs pueden perpetuar problemas lingüísticos y culturales sin tener un entendimiento real del significado, lo cual es problemático porque los modelos procesan lenguaje de manera probabilística, sin referencia a la realidad o al significado profundo.

### Narcisismo Tecnológico:

Judith Butler: La idea de que la tecnología puede lograr lo que se considera distintivamente humano o mejorar la humanidad puede llevar a una forma de narcisismo tecnológico, donde se busca demostrar que las máquinas pueden superar a los humanos en todas las capacidades.

### Creación de "Personas Falsas":

Daniel Dennett: La creación de "personas falsas" o entidades artificiales que imitan a los humanos plantea riesgos serios, ya que estas máquinas no tienen la capacidad de experimentar realmente la humanidad, lo cual puede llevar a una falta de responsabilidad y a la creación de "armas" que amenazan la estabilidad social.

### Riesgos de Confusión y Mal Uso:

Bender: La confusión y el mal uso potencial de los LLMs pueden resultar en una erosión de las barreras entre lo que es verdaderamente humano y lo que es artificial, lo cual puede tener consecuencias peligrosas para la sociedad.

### Defensa

Desde mí perspectiva no estoy de acuerdo con la mayoría del artículo.

Humanizar cosas no humanas es algo que hemos hecho mucho antes de que existieran las computadoras. Les damos nombres propios a nuestras mascotas, les hablamos como si nos entendieran, etc. Lo considero un comportamiento usual, el artículo no proporciona ningún fundamento para creer que esto contribuye a deshumanizar a otras personas, y no conozco ninguno.

Por otro lado, el punto de vista de Lemoine casi inverso al anterior, tampoco ofrece ningún fundamento. La deshumanización ha existido siempre y es anterior a las computadoras. Aunque actualmente la esclavitud y prácticas similares son ilegales en países occidentales, como sociedad debemos buscar combatirlas, y argumentos vagos y vacíos como este no contribuyen.

El punto de vista de Bender me parece válido. Los LLMs no representan a todas las personas por igual. Lo que puedan generar depende de los datos con los que fueron entrenados. Y si eventualmente se quieren utilizar para crear máquinas iguales a las personas, ese concepto de "persona" estaría sesgado.

La opinión de Judith Butler me parece puramente subjetivo. Ella hace un juicio de valor acerca de los objetivos que pueda tener la sociedad. No es discutible.

Estoy de acuerdo con la idea de Daniel Dennett y Bender. Pero como sociedad estamos ante la disyuntiva de desarrollar nuevas herramientas que puedan ser mal utilizadas o buscar la ignorancia.
